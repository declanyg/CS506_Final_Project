{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sSMADqS3aJH"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5n_IW5t3eXo"
   },
   "outputs": [],
   "source": [
    "API_KEY_ALPHA_VANTAGE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDOt0WRr3gPr"
   },
   "outputs": [],
   "source": [
    "def collect_news_data(query, api_key=API_KEY_ALPHA_VANTAGE):\n",
    "    \"\"\"Collect news headlines data from Alpha Vantage News API.\"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?{query}\" +f\"&apikey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    news_data = response.json()\n",
    "    headlines = [[item[key] for key in [\"title\", \"url\", \"time_published\", \"source\", \"overall_sentiment_score\", \"overall_sentiment_label\", \"ticker_sentiment\"]] for item in news_data.get(\"feed\", [])]\n",
    "    df = pd.DataFrame(headlines, columns=[\"title\", \"url\", \"time_published\", \"source\", \"overall_sentiment_score\", \"overall_sentiment_label\", \"ticker_sentiment\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdJ03Qc93hO4"
   },
   "outputs": [],
   "source": [
    "def get_data_from_date_range(start_time, end_time, saveFileName):\n",
    "  # Convert the string timestamps to pandas datetime objects\n",
    "  start_date = pd.to_datetime(start_time, format=\"%Y%m%dT%H%M\")\n",
    "  end_date = pd.to_datetime(end_time, format=\"%Y%m%dT%H%M\")\n",
    "\n",
    "  # Create a list to hold the date ranges\n",
    "  date_ranges = []\n",
    "\n",
    "  # Iterate from start_date to end_date in increments of 6 days\n",
    "  current_date = start_date\n",
    "  while current_date < end_date:\n",
    "      # Define the end date for the current interval\n",
    "      interval_end = current_date + pd.DateOffset(days=1)  # 6 days later (inclusive)\n",
    "\n",
    "      # Append the formatted date range to the list\n",
    "      date_ranges.append((current_date.strftime('%Y%m%dT0000'), interval_end.strftime('%Y%m%dT2359')))\n",
    "\n",
    "      # Move to the next interval\n",
    "      current_date += pd.DateOffset(days=1)\n",
    "\n",
    "  # Display the results\n",
    "  print(date_ranges)\n",
    "  print(len(date_ranges))\n",
    "\n",
    "  #Call apis\n",
    "  dfs = []\n",
    "\n",
    "  for start, end in date_ranges:\n",
    "    df = collect_news_data(f\"function=NEWS_SENTIMENT&topics=technology&time_from={start}&time_to={end}&sort=LATEST&limit=50\")\n",
    "    dfs.append(df)\n",
    "\n",
    "  merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "  merged_df['time_published'] = pd.to_datetime(merged_df['time_published'])\n",
    "\n",
    "  merged_df = merged_df.sort_values(by='time_published')\n",
    "\n",
    "  merged_df.to_csv(saveFileName, index=False)\n",
    "\n",
    "  print(len(merged_df))\n",
    "  display(merged_df)\n",
    "  return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTs5qqEL3o7K"
   },
   "outputs": [],
   "source": [
    "#Combine file fragments into 1 dataframe\n",
    "allFiles = []\n",
    "\n",
    "for i in range(1,5):\n",
    "  allFiles.append(pd.read_csv(f'technology_news_data_future_{i}.csv'))\n",
    "\n",
    "merged_vertical = pd.concat(allFiles, ignore_index=True)\n",
    "merged_vertical.to_csv('merged_technology_news_data_future_3months.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
