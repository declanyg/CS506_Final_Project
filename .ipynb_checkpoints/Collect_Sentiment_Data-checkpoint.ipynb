{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sSMADqS3aJH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY_ALPHA_VANTAGE = \"\""
      ],
      "metadata": {
        "id": "E5n_IW5t3eXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_news_data(query, api_key=API_KEY_ALPHA_VANTAGE):\n",
        "    \"\"\"Collect news headlines data from Alpha Vantage News API.\"\"\"\n",
        "    url = f\"https://www.alphavantage.co/query?{query}\" +f\"&apikey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    news_data = response.json()\n",
        "    headlines = [[item[key] for key in [\"title\", \"url\", \"time_published\", \"source\", \"overall_sentiment_score\", \"overall_sentiment_label\", \"ticker_sentiment\"]] for item in news_data.get(\"feed\", [])]\n",
        "    df = pd.DataFrame(headlines, columns=[\"title\", \"url\", \"time_published\", \"source\", \"overall_sentiment_score\", \"overall_sentiment_label\", \"ticker_sentiment\"])\n",
        "    return df"
      ],
      "metadata": {
        "id": "wDOt0WRr3gPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_date_range(start_time, end_time, saveFileName):\n",
        "  # Convert the string timestamps to pandas datetime objects\n",
        "  start_date = pd.to_datetime(start_time, format=\"%Y%m%dT%H%M\")\n",
        "  end_date = pd.to_datetime(end_time, format=\"%Y%m%dT%H%M\")\n",
        "\n",
        "  # Create a list to hold the date ranges\n",
        "  date_ranges = []\n",
        "\n",
        "  # Iterate from start_date to end_date in increments of 6 days\n",
        "  current_date = start_date\n",
        "  while current_date < end_date:\n",
        "      # Define the end date for the current interval\n",
        "      interval_end = current_date + pd.DateOffset(days=1)  # 6 days later (inclusive)\n",
        "\n",
        "      # Append the formatted date range to the list\n",
        "      date_ranges.append((current_date.strftime('%Y%m%dT0000'), interval_end.strftime('%Y%m%dT2359')))\n",
        "\n",
        "      # Move to the next interval\n",
        "      current_date += pd.DateOffset(days=1)\n",
        "\n",
        "  # Display the results\n",
        "  print(date_ranges)\n",
        "  print(len(date_ranges))\n",
        "\n",
        "  #Call apis\n",
        "  dfs = []\n",
        "\n",
        "  for start, end in date_ranges:\n",
        "    df = collect_news_data(f\"function=NEWS_SENTIMENT&topics=technology&time_from={start}&time_to={end}&sort=LATEST&limit=50\")\n",
        "    dfs.append(df)\n",
        "\n",
        "  merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "  merged_df['time_published'] = pd.to_datetime(merged_df['time_published'])\n",
        "\n",
        "  merged_df = merged_df.sort_values(by='time_published')\n",
        "\n",
        "  merged_df.to_csv(saveFileName, index=False)\n",
        "\n",
        "  print(len(merged_df))\n",
        "  display(merged_df)\n",
        "  return merged_df"
      ],
      "metadata": {
        "id": "mdJ03Qc93hO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine file fragments into 1 dataframe\n",
        "allFiles = []\n",
        "\n",
        "for i in range(1,5):\n",
        "  allFiles.append(pd.read_csv(f'technology_news_data_future_{i}.csv'))\n",
        "\n",
        "merged_vertical = pd.concat(allFiles, ignore_index=True)\n",
        "merged_vertical.to_csv('merged_technology_news_data_future_3months.csv', index=False)"
      ],
      "metadata": {
        "id": "aTs5qqEL3o7K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}